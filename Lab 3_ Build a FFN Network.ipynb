{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOtvBvjEUiFDwAynuVW9ka4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"bTrUJq3I5b0g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1691981753726,"user_tz":-330,"elapsed":18293,"user":{"displayName":"PIYUSH AGARWAL (RA2111047010152)","userId":"10536602745476787933"}},"outputId":"e93fd4e2-2d48-4c4a-baee-e1d96e328fbc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 64)                320       \n","                                                                 \n"," dense_1 (Dense)             (None, 32)                2080      \n","                                                                 \n"," dense_2 (Dense)             (None, 3)                 99        \n","                                                                 \n","=================================================================\n","Total params: 2,499\n","Trainable params: 2,499\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","7/7 [==============================] - 1s 42ms/step - loss: 1.0231 - accuracy: 0.4074 - val_loss: 1.0437 - val_accuracy: 0.4167\n","Epoch 2/100\n","7/7 [==============================] - 0s 7ms/step - loss: 0.8771 - accuracy: 0.6389 - val_loss: 0.9403 - val_accuracy: 0.6667\n","Epoch 3/100\n","7/7 [==============================] - 0s 7ms/step - loss: 0.7596 - accuracy: 0.7963 - val_loss: 0.8528 - val_accuracy: 0.7500\n","Epoch 4/100\n","7/7 [==============================] - 0s 7ms/step - loss: 0.6552 - accuracy: 0.8241 - val_loss: 0.7800 - val_accuracy: 0.7500\n","Epoch 5/100\n","7/7 [==============================] - 0s 10ms/step - loss: 0.5732 - accuracy: 0.8241 - val_loss: 0.7214 - val_accuracy: 0.7500\n","Epoch 6/100\n","7/7 [==============================] - 0s 11ms/step - loss: 0.5138 - accuracy: 0.8241 - val_loss: 0.6728 - val_accuracy: 0.7500\n","Epoch 7/100\n","7/7 [==============================] - 0s 11ms/step - loss: 0.4634 - accuracy: 0.8241 - val_loss: 0.6366 - val_accuracy: 0.7500\n","Epoch 8/100\n","7/7 [==============================] - 0s 8ms/step - loss: 0.4263 - accuracy: 0.8241 - val_loss: 0.6090 - val_accuracy: 0.7500\n","Epoch 9/100\n","7/7 [==============================] - 0s 8ms/step - loss: 0.3968 - accuracy: 0.8241 - val_loss: 0.5876 - val_accuracy: 0.8333\n","Epoch 10/100\n","7/7 [==============================] - 0s 11ms/step - loss: 0.3751 - accuracy: 0.8241 - val_loss: 0.5712 - val_accuracy: 0.8333\n","Epoch 11/100\n","7/7 [==============================] - 0s 10ms/step - loss: 0.3560 - accuracy: 0.8148 - val_loss: 0.5596 - val_accuracy: 0.8333\n","Epoch 12/100\n","7/7 [==============================] - 0s 10ms/step - loss: 0.3389 - accuracy: 0.8148 - val_loss: 0.5454 - val_accuracy: 0.8333\n","Epoch 13/100\n","7/7 [==============================] - 0s 10ms/step - loss: 0.3239 - accuracy: 0.8241 - val_loss: 0.5334 - val_accuracy: 0.8333\n","Epoch 14/100\n","7/7 [==============================] - 0s 11ms/step - loss: 0.3111 - accuracy: 0.8241 - val_loss: 0.5223 - val_accuracy: 0.8333\n","Epoch 15/100\n","7/7 [==============================] - 0s 8ms/step - loss: 0.2989 - accuracy: 0.8333 - val_loss: 0.5120 - val_accuracy: 0.8333\n","Epoch 16/100\n","7/7 [==============================] - 0s 11ms/step - loss: 0.2887 - accuracy: 0.8333 - val_loss: 0.5015 - val_accuracy: 0.8333\n","Epoch 17/100\n","7/7 [==============================] - 0s 11ms/step - loss: 0.2772 - accuracy: 0.8426 - val_loss: 0.4897 - val_accuracy: 0.9167\n","Epoch 18/100\n","7/7 [==============================] - 0s 13ms/step - loss: 0.2674 - accuracy: 0.8426 - val_loss: 0.4794 - val_accuracy: 0.9167\n","Epoch 19/100\n","7/7 [==============================] - 0s 10ms/step - loss: 0.2575 - accuracy: 0.8704 - val_loss: 0.4694 - val_accuracy: 0.9167\n","Epoch 20/100\n","7/7 [==============================] - 0s 7ms/step - loss: 0.2472 - accuracy: 0.8981 - val_loss: 0.4584 - val_accuracy: 0.9167\n","Epoch 21/100\n","7/7 [==============================] - 0s 10ms/step - loss: 0.2385 - accuracy: 0.8981 - val_loss: 0.4456 - val_accuracy: 0.9167\n","Epoch 22/100\n","7/7 [==============================] - 0s 7ms/step - loss: 0.2274 - accuracy: 0.8981 - val_loss: 0.4398 - val_accuracy: 0.9167\n","Epoch 23/100\n","7/7 [==============================] - 0s 7ms/step - loss: 0.2177 - accuracy: 0.9167 - val_loss: 0.4370 - val_accuracy: 0.9167\n","Epoch 24/100\n","7/7 [==============================] - 0s 7ms/step - loss: 0.2093 - accuracy: 0.9444 - val_loss: 0.4308 - val_accuracy: 0.9167\n","Epoch 25/100\n","7/7 [==============================] - 0s 7ms/step - loss: 0.1998 - accuracy: 0.9444 - val_loss: 0.4069 - val_accuracy: 0.9167\n","Epoch 26/100\n","7/7 [==============================] - 0s 7ms/step - loss: 0.1899 - accuracy: 0.9444 - val_loss: 0.3878 - val_accuracy: 0.9167\n","Epoch 27/100\n","7/7 [==============================] - 0s 7ms/step - loss: 0.1779 - accuracy: 0.9444 - val_loss: 0.3814 - val_accuracy: 0.9167\n","Epoch 28/100\n","7/7 [==============================] - 0s 7ms/step - loss: 0.1695 - accuracy: 0.9444 - val_loss: 0.3774 - val_accuracy: 0.9167\n","Epoch 29/100\n","7/7 [==============================] - 0s 12ms/step - loss: 0.1595 - accuracy: 0.9537 - val_loss: 0.3602 - val_accuracy: 0.9167\n","Epoch 30/100\n","7/7 [==============================] - 0s 7ms/step - loss: 0.1529 - accuracy: 0.9537 - val_loss: 0.3430 - val_accuracy: 0.9167\n","Epoch 31/100\n","7/7 [==============================] - 0s 7ms/step - loss: 0.1450 - accuracy: 0.9537 - val_loss: 0.3408 - val_accuracy: 0.9167\n","Epoch 32/100\n","7/7 [==============================] - 0s 7ms/step - loss: 0.1369 - accuracy: 0.9537 - val_loss: 0.3408 - val_accuracy: 0.9167\n","Epoch 33/100\n","7/7 [==============================] - 0s 7ms/step - loss: 0.1332 - accuracy: 0.9537 - val_loss: 0.3286 - val_accuracy: 0.9167\n","Epoch 34/100\n","7/7 [==============================] - 0s 7ms/step - loss: 0.1281 - accuracy: 0.9630 - val_loss: 0.3423 - val_accuracy: 0.9167\n","Epoch 35/100\n","7/7 [==============================] - 0s 7ms/step - loss: 0.1201 - accuracy: 0.9630 - val_loss: 0.3307 - val_accuracy: 0.9167\n","Epoch 36/100\n","7/7 [==============================] - 0s 7ms/step - loss: 0.1142 - accuracy: 0.9630 - val_loss: 0.3198 - val_accuracy: 0.9167\n","Epoch 37/100\n","7/7 [==============================] - 0s 10ms/step - loss: 0.1098 - accuracy: 0.9722 - val_loss: 0.3151 - val_accuracy: 0.9167\n","Epoch 38/100\n","7/7 [==============================] - 0s 7ms/step - loss: 0.1074 - accuracy: 0.9630 - val_loss: 0.3289 - val_accuracy: 0.9167\n","Epoch 39/100\n","7/7 [==============================] - 0s 7ms/step - loss: 0.1032 - accuracy: 0.9722 - val_loss: 0.3104 - val_accuracy: 0.9167\n","Epoch 40/100\n","7/7 [==============================] - 0s 7ms/step - loss: 0.0993 - accuracy: 0.9722 - val_loss: 0.3172 - val_accuracy: 0.9167\n","Epoch 41/100\n","7/7 [==============================] - 0s 9ms/step - loss: 0.0960 - accuracy: 0.9722 - val_loss: 0.3182 - val_accuracy: 0.9167\n","Epoch 42/100\n","7/7 [==============================] - 0s 7ms/step - loss: 0.0929 - accuracy: 0.9722 - val_loss: 0.3115 - val_accuracy: 0.9167\n","Epoch 43/100\n","7/7 [==============================] - 0s 7ms/step - loss: 0.0908 - accuracy: 0.9722 - val_loss: 0.3147 - val_accuracy: 0.9167\n","Epoch 44/100\n","7/7 [==============================] - 0s 8ms/step - loss: 0.0889 - accuracy: 0.9722 - val_loss: 0.3006 - val_accuracy: 0.9167\n","Epoch 45/100\n","7/7 [==============================] - 0s 7ms/step - loss: 0.0858 - accuracy: 0.9722 - val_loss: 0.2994 - val_accuracy: 0.9167\n","Epoch 46/100\n","7/7 [==============================] - 0s 8ms/step - loss: 0.0835 - accuracy: 0.9722 - val_loss: 0.2948 - val_accuracy: 0.9167\n","Epoch 47/100\n","7/7 [==============================] - 0s 8ms/step - loss: 0.0819 - accuracy: 0.9722 - val_loss: 0.3081 - val_accuracy: 0.9167\n","Epoch 48/100\n","7/7 [==============================] - 0s 7ms/step - loss: 0.0800 - accuracy: 0.9722 - val_loss: 0.3116 - val_accuracy: 0.9167\n","Epoch 49/100\n","7/7 [==============================] - 0s 11ms/step - loss: 0.0807 - accuracy: 0.9722 - val_loss: 0.2805 - val_accuracy: 0.9167\n","Epoch 50/100\n","7/7 [==============================] - 0s 7ms/step - loss: 0.0771 - accuracy: 0.9722 - val_loss: 0.2867 - val_accuracy: 0.9167\n","Epoch 51/100\n","7/7 [==============================] - 0s 7ms/step - loss: 0.0746 - accuracy: 0.9722 - val_loss: 0.3068 - val_accuracy: 0.9167\n","Epoch 52/100\n","7/7 [==============================] - 0s 7ms/step - loss: 0.0745 - accuracy: 0.9815 - val_loss: 0.3080 - val_accuracy: 0.9167\n","Epoch 53/100\n","7/7 [==============================] - 0s 8ms/step - loss: 0.0728 - accuracy: 0.9722 - val_loss: 0.2947 - val_accuracy: 0.9167\n","Epoch 54/100\n","7/7 [==============================] - 0s 8ms/step - loss: 0.0722 - accuracy: 0.9722 - val_loss: 0.3154 - val_accuracy: 0.9167\n","Epoch 55/100\n","7/7 [==============================] - 0s 8ms/step - loss: 0.0703 - accuracy: 0.9815 - val_loss: 0.3027 - val_accuracy: 0.9167\n","Epoch 56/100\n","7/7 [==============================] - 0s 10ms/step - loss: 0.0683 - accuracy: 0.9722 - val_loss: 0.2986 - val_accuracy: 0.9167\n","Epoch 57/100\n","7/7 [==============================] - 0s 11ms/step - loss: 0.0680 - accuracy: 0.9722 - val_loss: 0.2869 - val_accuracy: 0.9167\n","Epoch 58/100\n","7/7 [==============================] - 0s 11ms/step - loss: 0.0669 - accuracy: 0.9722 - val_loss: 0.2927 - val_accuracy: 0.9167\n","Epoch 59/100\n","7/7 [==============================] - 0s 11ms/step - loss: 0.0653 - accuracy: 0.9722 - val_loss: 0.2906 - val_accuracy: 0.9167\n","Epoch 60/100\n","7/7 [==============================] - 0s 8ms/step - loss: 0.0660 - accuracy: 0.9722 - val_loss: 0.3120 - val_accuracy: 0.9167\n","Epoch 61/100\n","7/7 [==============================] - 0s 11ms/step - loss: 0.0641 - accuracy: 0.9722 - val_loss: 0.3020 - val_accuracy: 0.9167\n","Epoch 62/100\n","7/7 [==============================] - 0s 14ms/step - loss: 0.0638 - accuracy: 0.9722 - val_loss: 0.3170 - val_accuracy: 0.9167\n","Epoch 63/100\n","7/7 [==============================] - 0s 20ms/step - loss: 0.0620 - accuracy: 0.9907 - val_loss: 0.3091 - val_accuracy: 0.9167\n","Epoch 64/100\n","7/7 [==============================] - 0s 16ms/step - loss: 0.0605 - accuracy: 0.9815 - val_loss: 0.3027 - val_accuracy: 0.9167\n","Epoch 65/100\n","7/7 [==============================] - 0s 14ms/step - loss: 0.0607 - accuracy: 0.9722 - val_loss: 0.2927 - val_accuracy: 0.9167\n","Epoch 66/100\n","7/7 [==============================] - 0s 15ms/step - loss: 0.0642 - accuracy: 0.9722 - val_loss: 0.3293 - val_accuracy: 0.9167\n","Epoch 67/100\n","7/7 [==============================] - 0s 14ms/step - loss: 0.0590 - accuracy: 0.9815 - val_loss: 0.2978 - val_accuracy: 0.9167\n","Epoch 68/100\n","7/7 [==============================] - 0s 16ms/step - loss: 0.0598 - accuracy: 0.9722 - val_loss: 0.2970 - val_accuracy: 0.9167\n","Epoch 69/100\n","7/7 [==============================] - 0s 18ms/step - loss: 0.0581 - accuracy: 0.9815 - val_loss: 0.3032 - val_accuracy: 0.9167\n","Epoch 70/100\n","7/7 [==============================] - 0s 17ms/step - loss: 0.0573 - accuracy: 0.9815 - val_loss: 0.2993 - val_accuracy: 0.9167\n","Epoch 71/100\n","7/7 [==============================] - 0s 20ms/step - loss: 0.0574 - accuracy: 0.9722 - val_loss: 0.2955 - val_accuracy: 0.9167\n","Epoch 72/100\n","7/7 [==============================] - 0s 20ms/step - loss: 0.0558 - accuracy: 0.9815 - val_loss: 0.3132 - val_accuracy: 0.9167\n","Epoch 73/100\n","7/7 [==============================] - 0s 16ms/step - loss: 0.0557 - accuracy: 0.9907 - val_loss: 0.3177 - val_accuracy: 0.9167\n","Epoch 74/100\n","7/7 [==============================] - 0s 19ms/step - loss: 0.0587 - accuracy: 0.9815 - val_loss: 0.3347 - val_accuracy: 0.9167\n","Epoch 75/100\n","7/7 [==============================] - 0s 15ms/step - loss: 0.0580 - accuracy: 0.9815 - val_loss: 0.3020 - val_accuracy: 0.9167\n","Epoch 76/100\n","7/7 [==============================] - 0s 12ms/step - loss: 0.0556 - accuracy: 0.9722 - val_loss: 0.3081 - val_accuracy: 0.9167\n","Epoch 77/100\n","7/7 [==============================] - 0s 14ms/step - loss: 0.0549 - accuracy: 0.9815 - val_loss: 0.3411 - val_accuracy: 0.9167\n","Epoch 78/100\n","7/7 [==============================] - 0s 24ms/step - loss: 0.0556 - accuracy: 0.9815 - val_loss: 0.3330 - val_accuracy: 0.9167\n","Epoch 79/100\n","7/7 [==============================] - 0s 17ms/step - loss: 0.0538 - accuracy: 0.9815 - val_loss: 0.3361 - val_accuracy: 0.9167\n","Epoch 80/100\n","7/7 [==============================] - 0s 23ms/step - loss: 0.0534 - accuracy: 0.9815 - val_loss: 0.3108 - val_accuracy: 0.9167\n","Epoch 81/100\n","7/7 [==============================] - 0s 19ms/step - loss: 0.0527 - accuracy: 0.9907 - val_loss: 0.3163 - val_accuracy: 0.9167\n","Epoch 82/100\n","7/7 [==============================] - 0s 25ms/step - loss: 0.0532 - accuracy: 0.9907 - val_loss: 0.3230 - val_accuracy: 0.9167\n","Epoch 83/100\n","7/7 [==============================] - 0s 18ms/step - loss: 0.0519 - accuracy: 0.9907 - val_loss: 0.3201 - val_accuracy: 0.9167\n","Epoch 84/100\n","7/7 [==============================] - 0s 16ms/step - loss: 0.0518 - accuracy: 0.9907 - val_loss: 0.3128 - val_accuracy: 0.9167\n","Epoch 85/100\n","7/7 [==============================] - 0s 17ms/step - loss: 0.0523 - accuracy: 0.9815 - val_loss: 0.3227 - val_accuracy: 0.9167\n","Epoch 86/100\n","7/7 [==============================] - 0s 17ms/step - loss: 0.0522 - accuracy: 0.9907 - val_loss: 0.3057 - val_accuracy: 0.9167\n","Epoch 87/100\n","7/7 [==============================] - 0s 25ms/step - loss: 0.0546 - accuracy: 0.9722 - val_loss: 0.3328 - val_accuracy: 0.9167\n","Epoch 88/100\n","7/7 [==============================] - 0s 21ms/step - loss: 0.0504 - accuracy: 0.9815 - val_loss: 0.3186 - val_accuracy: 0.9167\n","Epoch 89/100\n","7/7 [==============================] - 0s 15ms/step - loss: 0.0504 - accuracy: 0.9907 - val_loss: 0.3193 - val_accuracy: 0.9167\n","Epoch 90/100\n","7/7 [==============================] - 0s 16ms/step - loss: 0.0506 - accuracy: 0.9907 - val_loss: 0.3311 - val_accuracy: 0.9167\n","Epoch 91/100\n","7/7 [==============================] - 0s 20ms/step - loss: 0.0495 - accuracy: 0.9907 - val_loss: 0.3336 - val_accuracy: 0.9167\n","Epoch 92/100\n","7/7 [==============================] - 0s 20ms/step - loss: 0.0494 - accuracy: 0.9907 - val_loss: 0.3200 - val_accuracy: 0.9167\n","Epoch 93/100\n","7/7 [==============================] - 0s 19ms/step - loss: 0.0510 - accuracy: 0.9815 - val_loss: 0.3344 - val_accuracy: 0.9167\n","Epoch 94/100\n","7/7 [==============================] - 0s 16ms/step - loss: 0.0493 - accuracy: 0.9907 - val_loss: 0.3268 - val_accuracy: 0.9167\n","Epoch 95/100\n","7/7 [==============================] - 0s 23ms/step - loss: 0.0486 - accuracy: 0.9815 - val_loss: 0.3435 - val_accuracy: 0.9167\n","Epoch 96/100\n","7/7 [==============================] - 0s 19ms/step - loss: 0.0493 - accuracy: 0.9815 - val_loss: 0.3340 - val_accuracy: 0.9167\n","Epoch 97/100\n","7/7 [==============================] - 0s 37ms/step - loss: 0.0491 - accuracy: 0.9815 - val_loss: 0.3446 - val_accuracy: 0.9167\n","Epoch 98/100\n","7/7 [==============================] - 0s 36ms/step - loss: 0.0489 - accuracy: 0.9907 - val_loss: 0.3238 - val_accuracy: 0.9167\n","Epoch 99/100\n","7/7 [==============================] - 0s 37ms/step - loss: 0.0478 - accuracy: 0.9907 - val_loss: 0.3436 - val_accuracy: 0.9167\n","Epoch 100/100\n","7/7 [==============================] - 0s 25ms/step - loss: 0.0473 - accuracy: 0.9907 - val_loss: 0.3451 - val_accuracy: 0.9167\n","1/1 [==============================] - 0s 160ms/step - loss: 0.0257 - accuracy: 1.0000\n","Test loss: 0.0257, Test accuracy: 1.0000\n"]}],"source":["import numpy as np\n","from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.utils import to_categorical\n","\n","iris = load_iris()\n","X = iris.data\n","y = iris.target\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","y_train_cat = to_categorical(y_train)\n","y_test_cat = to_categorical(y_test)\n","\n","model = Sequential()\n","\n","model.add(Dense(64, input_dim=4, activation='relu'))\n","\n","model.add(Dense(32, activation='relu'))\n","\n","model.add(Dense(3, activation='softmax'))\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","model.summary()\n","\n","epochs = 100\n","batch_size = 16\n","validation_split = 0.1\n","\n","history = model.fit(X_train, y_train_cat, epochs=epochs, batch_size=batch_size, validation_split=validation_split)\n","\n","loss, accuracy = model.evaluate(X_test, y_test_cat)\n","print(f\"Test loss: {loss:.4f}, Test accuracy: {accuracy:.4f}\")\n"]}]}